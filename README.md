# ToxiGuard - Toxic Comment Detector with Explanations

This project detects toxic or harmful language in text using a fine-tuned BERT model. It also explains the modelâ€™s predictions using SHAP or LIME to promote responsible AI and interpretability.

## Features

- Detects toxic language in user input
- Uses a fine-tuned BERT model for classification
- Provides explanations for predictions using SHAP or LIME
- Django API for easy testing and integration

## Requirements

- Python 3.8+
- Django
- Transformers
- scikit-learn
- shap or lime
- torch
- pandas

Install dependencies:

```bash
pip install -r requirements.txt
